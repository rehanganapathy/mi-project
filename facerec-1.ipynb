{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        (os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-11-23T14:43:04.312878Z","iopub.execute_input":"2022-11-23T14:43:04.313206Z","iopub.status.idle":"2022-11-23T14:43:39.303645Z","shell.execute_reply.started":"2022-11-23T14:43:04.313158Z","shell.execute_reply":"2022-11-23T14:43:39.302685Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom keras.layers import Input, Lambda, Dense, Flatten\nfrom keras.models import Model\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.vgg16 import preprocess_input\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nimport random\nimport glob\nfrom glob import glob\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-11-23T14:43:39.306588Z","iopub.execute_input":"2022-11-23T14:43:39.307159Z","iopub.status.idle":"2022-11-23T14:43:40.610634Z","shell.execute_reply.started":"2022-11-23T14:43:39.307110Z","shell.execute_reply":"2022-11-23T14:43:40.609763Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"Using TensorFlow backend.\n","output_type":"stream"}]},{"cell_type":"code","source":"print(len('/kaggle/input/lfw-dataset/lfw-deepfunneled/lfw-deepfunneled'))","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2022-11-23T14:43:40.612099Z","iopub.execute_input":"2022-11-23T14:43:40.612556Z","iopub.status.idle":"2022-11-23T14:43:40.618325Z","shell.execute_reply.started":"2022-11-23T14:43:40.612507Z","shell.execute_reply":"2022-11-23T14:43:40.617228Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"59\n","output_type":"stream"}]},{"cell_type":"code","source":"root_path = '/kaggle/input/lfw-dataset/lfw-deepfunneled/lfw-deepfunneled/'","metadata":{"execution":{"iopub.status.busy":"2022-11-23T14:43:40.619578Z","iopub.execute_input":"2022-11-23T14:43:40.620104Z","iopub.status.idle":"2022-11-23T14:43:40.630017Z","shell.execute_reply.started":"2022-11-23T14:43:40.620066Z","shell.execute_reply":"2022-11-23T14:43:40.629082Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"folders = glob('/kaggle/input/lfw-dataset/lfw-deepfunneled/lfw-deepfunneled/*')\nlen(folders)","metadata":{"execution":{"iopub.status.busy":"2022-11-23T14:43:40.632392Z","iopub.execute_input":"2022-11-23T14:43:40.632748Z","iopub.status.idle":"2022-11-23T14:43:40.659399Z","shell.execute_reply.started":"2022-11-23T14:43:40.632713Z","shell.execute_reply":"2022-11-23T14:43:40.658526Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"5749"},"metadata":{}}]},{"cell_type":"code","source":"!pip install git+https://github.com/rcmalli/keras-vggface.git","metadata":{"execution":{"iopub.status.busy":"2022-11-23T14:43:40.661161Z","iopub.execute_input":"2022-11-23T14:43:40.661524Z","iopub.status.idle":"2022-11-23T14:43:51.911337Z","shell.execute_reply.started":"2022-11-23T14:43:40.661488Z","shell.execute_reply":"2022-11-23T14:43:51.910415Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/rcmalli/keras-vggface.git\n  Cloning https://github.com/rcmalli/keras-vggface.git to /tmp/pip-req-build-ek2l1rpu\n  Running command git clone -q https://github.com/rcmalli/keras-vggface.git /tmp/pip-req-build-ek2l1rpu\nRequirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras-vggface==0.6) (1.18.1)\nRequirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.7/site-packages (from keras-vggface==0.6) (1.4.1)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras-vggface==0.6) (2.10.0)\nRequirement already satisfied: pillow in /opt/conda/lib/python3.7/site-packages (from keras-vggface==0.6) (5.4.1)\nRequirement already satisfied: keras in /opt/conda/lib/python3.7/site-packages (from keras-vggface==0.6) (2.3.1)\nRequirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from keras-vggface==0.6) (1.14.0)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from keras-vggface==0.6) (5.3.1)\nRequirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.7/site-packages (from keras->keras-vggface==0.6) (1.1.2)\nRequirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.7/site-packages (from keras->keras-vggface==0.6) (1.0.8)\nBuilding wheels for collected packages: keras-vggface\n  Building wheel for keras-vggface (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for keras-vggface: filename=keras_vggface-0.6-py3-none-any.whl size=8310 sha256=5efc5d3d87776e21538312edfc2fd1fc3f271a4f2b6de617a3677632331062e7\n  Stored in directory: /tmp/pip-ephem-wheel-cache-io75y3kw/wheels/08/df/86/0225d44647ab2256dbf1e006823288fe9cc86367a056e6ea2c\nSuccessfully built keras-vggface\nInstalling collected packages: keras-vggface\nSuccessfully installed keras-vggface-0.6\n\u001b[33mWARNING: You are using pip version 20.1.1; however, version 22.3.1 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"from keras_vggface.vggface import VGGFace\nfrom keras.engine import  Model\nfrom keras.layers import Input","metadata":{"execution":{"iopub.status.busy":"2022-11-23T14:44:00.799365Z","iopub.execute_input":"2022-11-23T14:44:00.799743Z","iopub.status.idle":"2022-11-23T14:44:00.811928Z","shell.execute_reply.started":"2022-11-23T14:44:00.799707Z","shell.execute_reply":"2022-11-23T14:44:00.810905Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"vgg = VGGFace(include_top=False, weights='vggface',input_tensor=None, input_shape=[224, 224, 3]) ","metadata":{"execution":{"iopub.status.busy":"2022-11-23T14:44:04.046967Z","iopub.execute_input":"2022-11-23T14:44:04.047338Z","iopub.status.idle":"2022-11-23T14:44:06.448079Z","shell.execute_reply.started":"2022-11-23T14:44:04.047307Z","shell.execute_reply":"2022-11-23T14:44:06.447212Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Downloading data from https://github.com/rcmalli/keras-vggface/releases/download/v2.0/rcmalli_vggface_tf_notop_vgg16.h5\n58916864/58909280 [==============================] - 1s 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"for layer in vgg.layers:\n  layer.trainable = False","metadata":{"execution":{"iopub.status.busy":"2022-11-23T14:44:07.537408Z","iopub.execute_input":"2022-11-23T14:44:07.537725Z","iopub.status.idle":"2022-11-23T14:44:07.542473Z","shell.execute_reply.started":"2022-11-23T14:44:07.537697Z","shell.execute_reply":"2022-11-23T14:44:07.541173Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"x = Flatten()(vgg.output)\nx = Dense(1000, activation='relu')(x)\nx = Dense(1000, activation='relu')(x)\nprediction = Dense(len(folders), activation='softmax')(x)","metadata":{"execution":{"iopub.status.busy":"2022-11-23T14:44:10.181656Z","iopub.execute_input":"2022-11-23T14:44:10.181986Z","iopub.status.idle":"2022-11-23T14:44:10.215733Z","shell.execute_reply.started":"2022-11-23T14:44:10.181957Z","shell.execute_reply":"2022-11-23T14:44:10.214904Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"model = Model(inputs=vgg.input, outputs=prediction)","metadata":{"execution":{"iopub.status.busy":"2022-11-23T14:44:12.019275Z","iopub.execute_input":"2022-11-23T14:44:12.019595Z","iopub.status.idle":"2022-11-23T14:44:12.026152Z","shell.execute_reply.started":"2022-11-23T14:44:12.019566Z","shell.execute_reply":"2022-11-23T14:44:12.025255Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-11-23T14:44:21.110887Z","iopub.execute_input":"2022-11-23T14:44:21.111239Z","iopub.status.idle":"2022-11-23T14:44:21.126213Z","shell.execute_reply.started":"2022-11-23T14:44:21.111199Z","shell.execute_reply":"2022-11-23T14:44:21.125490Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Model: \"model_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         (None, 224, 224, 3)       0         \n_________________________________________________________________\nconv1_1 (Conv2D)             (None, 224, 224, 64)      1792      \n_________________________________________________________________\nconv1_2 (Conv2D)             (None, 224, 224, 64)      36928     \n_________________________________________________________________\npool1 (MaxPooling2D)         (None, 112, 112, 64)      0         \n_________________________________________________________________\nconv2_1 (Conv2D)             (None, 112, 112, 128)     73856     \n_________________________________________________________________\nconv2_2 (Conv2D)             (None, 112, 112, 128)     147584    \n_________________________________________________________________\npool2 (MaxPooling2D)         (None, 56, 56, 128)       0         \n_________________________________________________________________\nconv3_1 (Conv2D)             (None, 56, 56, 256)       295168    \n_________________________________________________________________\nconv3_2 (Conv2D)             (None, 56, 56, 256)       590080    \n_________________________________________________________________\nconv3_3 (Conv2D)             (None, 56, 56, 256)       590080    \n_________________________________________________________________\npool3 (MaxPooling2D)         (None, 28, 28, 256)       0         \n_________________________________________________________________\nconv4_1 (Conv2D)             (None, 28, 28, 512)       1180160   \n_________________________________________________________________\nconv4_2 (Conv2D)             (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nconv4_3 (Conv2D)             (None, 28, 28, 512)       2359808   \n_________________________________________________________________\npool4 (MaxPooling2D)         (None, 14, 14, 512)       0         \n_________________________________________________________________\nconv5_1 (Conv2D)             (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nconv5_2 (Conv2D)             (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nconv5_3 (Conv2D)             (None, 14, 14, 512)       2359808   \n_________________________________________________________________\npool5 (MaxPooling2D)         (None, 7, 7, 512)         0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 25088)             0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 1000)              25089000  \n_________________________________________________________________\ndense_2 (Dense)              (None, 1000)              1001000   \n_________________________________________________________________\ndense_3 (Dense)              (None, 5749)              5754749   \n=================================================================\nTotal params: 46,559,437\nTrainable params: 31,844,749\nNon-trainable params: 14,714,688\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.layers import Input, Conv2D\nfrom tensorflow.keras.layers import MaxPool2D, Flatten, Dense\nfrom tensorflow.keras import Model\n","metadata":{"execution":{"iopub.status.busy":"2022-11-23T16:15:58.181626Z","iopub.execute_input":"2022-11-23T16:15:58.181941Z","iopub.status.idle":"2022-11-23T16:15:58.186335Z","shell.execute_reply.started":"2022-11-23T16:15:58.181912Z","shell.execute_reply":"2022-11-23T16:15:58.185468Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"input = Input(shape =(224,224,3))\n\n# 1st Conv Block\n\nx = Conv2D (filters =64, kernel_size =3, padding ='same', activation='relu')(input)\nx = Conv2D (filters =64, kernel_size =3, padding ='same', activation='relu')(x)\nx = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n\n# 2nd Conv Block\n\nx = Conv2D (filters =128, kernel_size =3, padding ='same', activation='relu')(x)\nx = Conv2D (filters =128, kernel_size =3, padding ='same', activation='relu')(x)\nx = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n\n# 3rd Conv block  \nx = Conv2D (filters =256, kernel_size =3, padding ='same', activation='relu')(x) \nx = Conv2D (filters =256, kernel_size =3, padding ='same', activation='relu')(x) \nx = Conv2D (filters =256, kernel_size =3, padding ='same', activation='relu')(x) \nx = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n\n# 4th Conv block\n\nx = Conv2D (filters =512, kernel_size =3, padding ='same', activation='relu')(x)\nx = Conv2D (filters =512, kernel_size =3, padding ='same', activation='relu')(x)\nx = Conv2D (filters =512, kernel_size =3, padding ='same', activation='relu')(x)\nx = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n\n# 5th Conv block\n\nx = Conv2D (filters =512, kernel_size =3, padding ='same', activation='relu')(x)\nx = Conv2D (filters =512, kernel_size =3, padding ='same', activation='relu')(x)\nx = Conv2D (filters =512, kernel_size =3, padding ='same', activation='relu')(x)\nx = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n\n# Fully connected layers  \nx = Flatten()(x) \nx = Dense(units = 4096, activation ='relu')(x) \nx = Dense(units = 4096, activation ='relu')(x) \noutput = Dense(units = 5749, activation ='softmax')(x)","metadata":{"execution":{"iopub.status.busy":"2022-11-23T16:18:14.232737Z","iopub.execute_input":"2022-11-23T16:18:14.233069Z","iopub.status.idle":"2022-11-23T16:18:14.404597Z","shell.execute_reply.started":"2022-11-23T16:18:14.233036Z","shell.execute_reply":"2022-11-23T16:18:14.403860Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"code","source":"model1 = Model (inputs=input, outputs =output)\nmodel1.summary()","metadata":{"execution":{"iopub.status.busy":"2022-11-23T16:18:17.598092Z","iopub.execute_input":"2022-11-23T16:18:17.598434Z","iopub.status.idle":"2022-11-23T16:18:17.618133Z","shell.execute_reply.started":"2022-11-23T16:18:17.598403Z","shell.execute_reply":"2022-11-23T16:18:17.617398Z"},"trusted":true},"execution_count":97,"outputs":[{"name":"stdout","text":"Model: \"model_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_3 (InputLayer)         [(None, 224, 224, 3)]     0         \n_________________________________________________________________\nconv2d_263 (Conv2D)          (None, 224, 224, 64)      1792      \n_________________________________________________________________\nconv2d_264 (Conv2D)          (None, 224, 224, 64)      36928     \n_________________________________________________________________\nmax_pooling2d_102 (MaxPoolin (None, 112, 112, 64)      0         \n_________________________________________________________________\nconv2d_265 (Conv2D)          (None, 112, 112, 128)     73856     \n_________________________________________________________________\nconv2d_266 (Conv2D)          (None, 112, 112, 128)     147584    \n_________________________________________________________________\nmax_pooling2d_103 (MaxPoolin (None, 56, 56, 128)       0         \n_________________________________________________________________\nconv2d_267 (Conv2D)          (None, 56, 56, 256)       295168    \n_________________________________________________________________\nconv2d_268 (Conv2D)          (None, 56, 56, 256)       590080    \n_________________________________________________________________\nconv2d_269 (Conv2D)          (None, 56, 56, 256)       590080    \n_________________________________________________________________\nmax_pooling2d_104 (MaxPoolin (None, 28, 28, 256)       0         \n_________________________________________________________________\nconv2d_270 (Conv2D)          (None, 28, 28, 512)       1180160   \n_________________________________________________________________\nconv2d_271 (Conv2D)          (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nconv2d_272 (Conv2D)          (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nmax_pooling2d_105 (MaxPoolin (None, 14, 14, 512)       0         \n_________________________________________________________________\nconv2d_273 (Conv2D)          (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nconv2d_274 (Conv2D)          (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nconv2d_275 (Conv2D)          (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nmax_pooling2d_106 (MaxPoolin (None, 7, 7, 512)         0         \n_________________________________________________________________\nflatten_20 (Flatten)         (None, 25088)             0         \n_________________________________________________________________\ndense_60 (Dense)             (None, 4096)              102764544 \n_________________________________________________________________\ndense_61 (Dense)             (None, 4096)              16781312  \n_________________________________________________________________\ndense_62 (Dense)             (None, 5749)              23553653  \n=================================================================\nTotal params: 157,814,197\nTrainable params: 157,814,197\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model1.compile(\n  loss='categorical_crossentropy',\n  optimizer='adam',\n  metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2022-11-23T16:18:22.135669Z","iopub.execute_input":"2022-11-23T16:18:22.135987Z","iopub.status.idle":"2022-11-23T16:18:22.148346Z","shell.execute_reply.started":"2022-11-23T16:18:22.135957Z","shell.execute_reply":"2022-11-23T16:18:22.147364Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"code","source":"import os\nimport random\nfrom shutil import copyfile\n\ndef img_train_test_split(img_source_dir, train_size):\n    \"\"\"\n    Randomly splits images over a train and validation folder, while preserving the folder structure\n    \n    Parameters\n    ----------\n    img_source_dir : string\n        Path to the folder with the images to be split. Can be absolute or relative path   \n        \n    train_size : float\n        Proportion of the original images that need to be copied in the subdirectory in the train folder\n    \"\"\"    \n    if not (isinstance(img_source_dir, str)):\n        raise AttributeError('img_source_dir must be a string')\n        \n    if not os.path.exists(img_source_dir):\n        raise OSError('img_source_dir does not exist')\n        \n    if not (isinstance(train_size, float)):\n        raise AttributeError('train_size must be a float')\n        \n    # Set up empty folder structure if not exists\n    if not os.path.exists('data'):\n        os.makedirs('data')\n    else:\n        if not os.path.exists('data/train'):\n            os.makedirs('data/train')\n        if not os.path.exists('data/validation'):\n            os.makedirs('data/validation')\n            \n    # Get the subdirectories in the main image folder\n    subdirs = [subdir for subdir in os.listdir(img_source_dir) if os.path.isdir(os.path.join(img_source_dir, subdir))]\n\n    for subdir in subdirs:\n        subdir_fullpath = os.path.join(img_source_dir, subdir)\n        if len(os.listdir(subdir_fullpath)) == 0:\n            print(subdir_fullpath + ' is empty')\n            break\n\n        train_subdir = os.path.join('data/train', subdir)\n        validation_subdir = os.path.join('data/validation', subdir)\n\n        # Create subdirectories in train and validation folders\n        if not os.path.exists(train_subdir):\n            os.makedirs(train_subdir)\n\n        if not os.path.exists(validation_subdir):\n            os.makedirs(validation_subdir)\n\n        train_counter = 0\n        validation_counter = 0\n\n        # Randomly assign an image to train or validation folder\n        for filename in os.listdir(subdir_fullpath):\n            if filename.endswith(\".jpg\") or filename.endswith(\".png\"): \n                fileparts = filename.split('.')\n\n                if random.uniform(0, 1) <= train_size:\n                    copyfile(os.path.join(subdir_fullpath, filename), os.path.join(train_subdir, str(train_counter) + '.' + fileparts[1]))\n                    train_counter += 1\n                else:\n                    copyfile(os.path.join(subdir_fullpath, filename), os.path.join(validation_subdir, str(validation_counter) + '.' + fileparts[1]))\n                    validation_counter += 1\n                    \n","metadata":{"execution":{"iopub.status.busy":"2022-11-23T14:47:29.246102Z","iopub.execute_input":"2022-11-23T14:47:29.246473Z","iopub.status.idle":"2022-11-23T14:47:29.261109Z","shell.execute_reply.started":"2022-11-23T14:47:29.246441Z","shell.execute_reply":"2022-11-23T14:47:29.260250Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"img_train_test_split(root_path, train_size=0.7)","metadata":{"execution":{"iopub.status.busy":"2022-11-23T14:47:34.398212Z","iopub.execute_input":"2022-11-23T14:47:34.398536Z","iopub.status.idle":"2022-11-23T14:50:02.285231Z","shell.execute_reply.started":"2022-11-23T14:47:34.398506Z","shell.execute_reply":"2022-11-23T14:50:02.284445Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"train = glob('data/train/*')\nprint(len(train))\nvalidation = glob('data/validation/*')\nprint(len(validation))","metadata":{"execution":{"iopub.status.busy":"2022-11-23T14:50:04.917544Z","iopub.execute_input":"2022-11-23T14:50:04.917861Z","iopub.status.idle":"2022-11-23T14:50:04.957203Z","shell.execute_reply.started":"2022-11-23T14:50:04.917832Z","shell.execute_reply":"2022-11-23T14:50:04.956309Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"5749\n5749\n","output_type":"stream"}]},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\ntrain_datagen = ImageDataGenerator(rescale = 1./255,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   horizontal_flip = True)\n\ntest_datagen = ImageDataGenerator(rescale = 1./255)\n\ntraining_set = train_datagen.flow_from_directory('data/train',\n                                                 target_size = (224, 224),\n                                                 batch_size = 32,\n                                                 class_mode = 'categorical')\n\ntest_set = test_datagen.flow_from_directory('data/validation',\n                                            target_size = (224, 224),\n                                            batch_size = 32,\n                                            class_mode = 'categorical')\ntest_steps_per_epoch = np.math.ceil(test_set.samples / test_set.batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-11-23T14:50:08.415922Z","iopub.execute_input":"2022-11-23T14:50:08.416258Z","iopub.status.idle":"2022-11-23T14:50:10.762058Z","shell.execute_reply.started":"2022-11-23T14:50:08.416226Z","shell.execute_reply":"2022-11-23T14:50:10.761159Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"Found 9250 images belonging to 5749 classes.\nFound 3983 images belonging to 5749 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"r = model2.fit(\n  training_set,\n  validation_data=test_set,\n  epochs=15,\n  steps_per_epoch=len(training_set),\n  validation_steps=len(test_set),\n)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-11-23T16:48:11.700497Z","iopub.execute_input":"2022-11-23T16:48:11.700811Z","iopub.status.idle":"2022-11-23T16:48:16.998825Z","shell.execute_reply.started":"2022-11-23T16:48:11.700782Z","shell.execute_reply":"2022-11-23T16:48:16.996563Z"},"trusted":true},"execution_count":115,"outputs":[{"name":"stdout","text":"Epoch 1/15\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-115-453ae5931342>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m )\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m:  logits and labels must have the same first dimension, got logits shape [32,10] and labels shape [183968]\n\t [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at <ipython-input-115-453ae5931342>:6) ]] [Op:__inference_train_function_69015]\n\nFunction call stack:\ntrain_function\n"],"ename":"InvalidArgumentError","evalue":" logits and labels must have the same first dimension, got logits shape [32,10] and labels shape [183968]\n\t [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at <ipython-input-115-453ae5931342>:6) ]] [Op:__inference_train_function_69015]\n\nFunction call stack:\ntrain_function\n","output_type":"error"}]},{"cell_type":"code","source":"def convolutional_block(x, filter):\n    # copy tensor to variable called x_skip\n    x_skip = x\n    # Layer 1\n    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same', strides = (2,2))(x)\n    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n    x = tf.keras.layers.Activation('relu')(x)\n    # Layer 2\n    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n    # Processing Residue with conv(1,1)\n    x_skip = tf.keras.layers.Conv2D(filter, (1,1), strides = (2,2))(x_skip)\n    # Add Residue\n    x = tf.keras.layers.Add()([x, x_skip])     \n    x = tf.keras.layers.Activation('relu')(x)\n    return x\n\ndef identity_block(x, filter):\n    \n    # copy tensor to variable called x_skip\n    x_skip = x\n    \n    # Layer 1\n    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n    x = tf.keras.layers.Activation('relu')(x)\n    \n    # Layer 2\n    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n    \n    # Add Residue\n    x = tf.keras.layers.Add()([x, x_skip])     \n    x = tf.keras.layers.Activation('relu')(x)\n    \n    return x","metadata":{"execution":{"iopub.status.busy":"2022-11-23T16:47:39.713701Z","iopub.execute_input":"2022-11-23T16:47:39.714029Z","iopub.status.idle":"2022-11-23T16:47:39.725209Z","shell.execute_reply.started":"2022-11-23T16:47:39.714000Z","shell.execute_reply":"2022-11-23T16:47:39.724043Z"},"trusted":true},"execution_count":112,"outputs":[]},{"cell_type":"code","source":"def ResNet34(shape = (224, 224, 3), classes = 10):\n    # Step 1 (Setup Input Layer)\n    x_input = tf.keras.layers.Input(shape)\n    x = tf.keras.layers.ZeroPadding2D((3, 3))(x_input)\n    # Step 2 (Initial Conv layer along with maxPool)\n    x = tf.keras.layers.Conv2D(64, kernel_size=7, strides=2, padding='same')(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Activation('relu')(x)\n    x = tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same')(x)\n    # Define size of sub-blocks and initial filter size\n    block_layers = [3, 4, 6, 3]\n    filter_size = 64\n    # Step 3 Add the Resnet Blocks\n    for i in range(4):\n        if i == 0:\n            # For sub-block 1 Residual/Convolutional block not needed\n            for j in range(block_layers[i]):\n                x = identity_block(x, filter_size)\n        else:\n            # One Residual/Convolutional Block followed by Identity blocks\n            # The filter size will go on increasing by a factor of 2\n            filter_size = filter_size*2\n            x = convolutional_block(x, filter_size)\n            for j in range(block_layers[i] - 1):\n                x = identity_block(x, filter_size)\n    # Step 4 End Dense Network\n    x = tf.keras.layers.AveragePooling2D((2,2), padding = 'same')(x)\n    x = tf.keras.layers.Flatten()(x)\n    x = tf.keras.layers.Dense(512, activation = 'relu')(x)\n    x = tf.keras.layers.Dense(5749, activation = 'softmax')(x)\n    model2 = tf.keras.models.Model(inputs = x_input, outputs = x, name = \"ResNet34\")\n    return model2","metadata":{"execution":{"iopub.status.busy":"2022-11-23T16:58:15.579525Z","iopub.execute_input":"2022-11-23T16:58:15.579934Z","iopub.status.idle":"2022-11-23T16:58:15.590932Z","shell.execute_reply.started":"2022-11-23T16:58:15.579903Z","shell.execute_reply":"2022-11-23T16:58:15.590042Z"},"trusted":true},"execution_count":124,"outputs":[]},{"cell_type":"code","source":"model2 = ResNet34()\nmodel2.compile(optimizer = 'adam', loss='categorical_crossentropy', metrics = ['accuracy'])\nmodel2.summary()","metadata":{"execution":{"iopub.status.busy":"2022-11-23T16:58:19.335131Z","iopub.execute_input":"2022-11-23T16:58:19.335512Z","iopub.status.idle":"2022-11-23T16:58:21.489294Z","shell.execute_reply.started":"2022-11-23T16:58:19.335477Z","shell.execute_reply":"2022-11-23T16:58:21.488439Z"},"trusted":true},"execution_count":125,"outputs":[{"name":"stdout","text":"Model: \"ResNet34\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_9 (InputLayer)            [(None, 224, 224, 3) 0                                            \n__________________________________________________________________________________________________\nzero_padding2d_5 (ZeroPadding2D (None, 230, 230, 3)  0           input_9[0][0]                    \n__________________________________________________________________________________________________\nconv2d_421 (Conv2D)             (None, 115, 115, 64) 9472        zero_padding2d_5[0][0]           \n__________________________________________________________________________________________________\nbatch_normalization_211 (BatchN (None, 115, 115, 64) 256         conv2d_421[0][0]                 \n__________________________________________________________________________________________________\nactivation_133 (Activation)     (None, 115, 115, 64) 0           batch_normalization_211[0][0]    \n__________________________________________________________________________________________________\nmax_pooling2d_112 (MaxPooling2D (None, 58, 58, 64)   0           activation_133[0][0]             \n__________________________________________________________________________________________________\nconv2d_422 (Conv2D)             (None, 58, 58, 64)   36928       max_pooling2d_112[0][0]          \n__________________________________________________________________________________________________\nbatch_normalization_212 (BatchN (None, 58, 58, 64)   256         conv2d_422[0][0]                 \n__________________________________________________________________________________________________\nactivation_134 (Activation)     (None, 58, 58, 64)   0           batch_normalization_212[0][0]    \n__________________________________________________________________________________________________\nconv2d_423 (Conv2D)             (None, 58, 58, 64)   36928       activation_134[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_213 (BatchN (None, 58, 58, 64)   256         conv2d_423[0][0]                 \n__________________________________________________________________________________________________\nadd_64 (Add)                    (None, 58, 58, 64)   0           batch_normalization_213[0][0]    \n                                                                 max_pooling2d_112[0][0]          \n__________________________________________________________________________________________________\nactivation_135 (Activation)     (None, 58, 58, 64)   0           add_64[0][0]                     \n__________________________________________________________________________________________________\nconv2d_424 (Conv2D)             (None, 58, 58, 64)   36928       activation_135[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_214 (BatchN (None, 58, 58, 64)   256         conv2d_424[0][0]                 \n__________________________________________________________________________________________________\nactivation_136 (Activation)     (None, 58, 58, 64)   0           batch_normalization_214[0][0]    \n__________________________________________________________________________________________________\nconv2d_425 (Conv2D)             (None, 58, 58, 64)   36928       activation_136[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_215 (BatchN (None, 58, 58, 64)   256         conv2d_425[0][0]                 \n__________________________________________________________________________________________________\nadd_65 (Add)                    (None, 58, 58, 64)   0           batch_normalization_215[0][0]    \n                                                                 activation_135[0][0]             \n__________________________________________________________________________________________________\nactivation_137 (Activation)     (None, 58, 58, 64)   0           add_65[0][0]                     \n__________________________________________________________________________________________________\nconv2d_426 (Conv2D)             (None, 58, 58, 64)   36928       activation_137[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_216 (BatchN (None, 58, 58, 64)   256         conv2d_426[0][0]                 \n__________________________________________________________________________________________________\nactivation_138 (Activation)     (None, 58, 58, 64)   0           batch_normalization_216[0][0]    \n__________________________________________________________________________________________________\nconv2d_427 (Conv2D)             (None, 58, 58, 64)   36928       activation_138[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_217 (BatchN (None, 58, 58, 64)   256         conv2d_427[0][0]                 \n__________________________________________________________________________________________________\nadd_66 (Add)                    (None, 58, 58, 64)   0           batch_normalization_217[0][0]    \n                                                                 activation_137[0][0]             \n__________________________________________________________________________________________________\nactivation_139 (Activation)     (None, 58, 58, 64)   0           add_66[0][0]                     \n__________________________________________________________________________________________________\nconv2d_428 (Conv2D)             (None, 29, 29, 128)  73856       activation_139[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_218 (BatchN (None, 29, 29, 128)  512         conv2d_428[0][0]                 \n__________________________________________________________________________________________________\nactivation_140 (Activation)     (None, 29, 29, 128)  0           batch_normalization_218[0][0]    \n__________________________________________________________________________________________________\nconv2d_429 (Conv2D)             (None, 29, 29, 128)  147584      activation_140[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_219 (BatchN (None, 29, 29, 128)  512         conv2d_429[0][0]                 \n__________________________________________________________________________________________________\nconv2d_430 (Conv2D)             (None, 29, 29, 128)  8320        activation_139[0][0]             \n__________________________________________________________________________________________________\nadd_67 (Add)                    (None, 29, 29, 128)  0           batch_normalization_219[0][0]    \n                                                                 conv2d_430[0][0]                 \n__________________________________________________________________________________________________\nactivation_141 (Activation)     (None, 29, 29, 128)  0           add_67[0][0]                     \n__________________________________________________________________________________________________\nconv2d_431 (Conv2D)             (None, 29, 29, 128)  147584      activation_141[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_220 (BatchN (None, 29, 29, 128)  512         conv2d_431[0][0]                 \n__________________________________________________________________________________________________\nactivation_142 (Activation)     (None, 29, 29, 128)  0           batch_normalization_220[0][0]    \n__________________________________________________________________________________________________\nconv2d_432 (Conv2D)             (None, 29, 29, 128)  147584      activation_142[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_221 (BatchN (None, 29, 29, 128)  512         conv2d_432[0][0]                 \n__________________________________________________________________________________________________\nadd_68 (Add)                    (None, 29, 29, 128)  0           batch_normalization_221[0][0]    \n                                                                 activation_141[0][0]             \n__________________________________________________________________________________________________\nactivation_143 (Activation)     (None, 29, 29, 128)  0           add_68[0][0]                     \n__________________________________________________________________________________________________\nconv2d_433 (Conv2D)             (None, 29, 29, 128)  147584      activation_143[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_222 (BatchN (None, 29, 29, 128)  512         conv2d_433[0][0]                 \n__________________________________________________________________________________________________\nactivation_144 (Activation)     (None, 29, 29, 128)  0           batch_normalization_222[0][0]    \n__________________________________________________________________________________________________\nconv2d_434 (Conv2D)             (None, 29, 29, 128)  147584      activation_144[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_223 (BatchN (None, 29, 29, 128)  512         conv2d_434[0][0]                 \n__________________________________________________________________________________________________\nadd_69 (Add)                    (None, 29, 29, 128)  0           batch_normalization_223[0][0]    \n                                                                 activation_143[0][0]             \n__________________________________________________________________________________________________\nactivation_145 (Activation)     (None, 29, 29, 128)  0           add_69[0][0]                     \n__________________________________________________________________________________________________\nconv2d_435 (Conv2D)             (None, 29, 29, 128)  147584      activation_145[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_224 (BatchN (None, 29, 29, 128)  512         conv2d_435[0][0]                 \n__________________________________________________________________________________________________\nactivation_146 (Activation)     (None, 29, 29, 128)  0           batch_normalization_224[0][0]    \n__________________________________________________________________________________________________\nconv2d_436 (Conv2D)             (None, 29, 29, 128)  147584      activation_146[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_225 (BatchN (None, 29, 29, 128)  512         conv2d_436[0][0]                 \n__________________________________________________________________________________________________\nadd_70 (Add)                    (None, 29, 29, 128)  0           batch_normalization_225[0][0]    \n                                                                 activation_145[0][0]             \n__________________________________________________________________________________________________\nactivation_147 (Activation)     (None, 29, 29, 128)  0           add_70[0][0]                     \n__________________________________________________________________________________________________\nconv2d_437 (Conv2D)             (None, 15, 15, 256)  295168      activation_147[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_226 (BatchN (None, 15, 15, 256)  1024        conv2d_437[0][0]                 \n__________________________________________________________________________________________________\nactivation_148 (Activation)     (None, 15, 15, 256)  0           batch_normalization_226[0][0]    \n__________________________________________________________________________________________________\nconv2d_438 (Conv2D)             (None, 15, 15, 256)  590080      activation_148[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_227 (BatchN (None, 15, 15, 256)  1024        conv2d_438[0][0]                 \n__________________________________________________________________________________________________\nconv2d_439 (Conv2D)             (None, 15, 15, 256)  33024       activation_147[0][0]             \n__________________________________________________________________________________________________\nadd_71 (Add)                    (None, 15, 15, 256)  0           batch_normalization_227[0][0]    \n                                                                 conv2d_439[0][0]                 \n__________________________________________________________________________________________________\nactivation_149 (Activation)     (None, 15, 15, 256)  0           add_71[0][0]                     \n__________________________________________________________________________________________________\nconv2d_440 (Conv2D)             (None, 15, 15, 256)  590080      activation_149[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_228 (BatchN (None, 15, 15, 256)  1024        conv2d_440[0][0]                 \n__________________________________________________________________________________________________\nactivation_150 (Activation)     (None, 15, 15, 256)  0           batch_normalization_228[0][0]    \n__________________________________________________________________________________________________\nconv2d_441 (Conv2D)             (None, 15, 15, 256)  590080      activation_150[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_229 (BatchN (None, 15, 15, 256)  1024        conv2d_441[0][0]                 \n__________________________________________________________________________________________________\nadd_72 (Add)                    (None, 15, 15, 256)  0           batch_normalization_229[0][0]    \n                                                                 activation_149[0][0]             \n__________________________________________________________________________________________________\nactivation_151 (Activation)     (None, 15, 15, 256)  0           add_72[0][0]                     \n__________________________________________________________________________________________________\nconv2d_442 (Conv2D)             (None, 15, 15, 256)  590080      activation_151[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_230 (BatchN (None, 15, 15, 256)  1024        conv2d_442[0][0]                 \n__________________________________________________________________________________________________\nactivation_152 (Activation)     (None, 15, 15, 256)  0           batch_normalization_230[0][0]    \n__________________________________________________________________________________________________\nconv2d_443 (Conv2D)             (None, 15, 15, 256)  590080      activation_152[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_231 (BatchN (None, 15, 15, 256)  1024        conv2d_443[0][0]                 \n__________________________________________________________________________________________________\nadd_73 (Add)                    (None, 15, 15, 256)  0           batch_normalization_231[0][0]    \n                                                                 activation_151[0][0]             \n__________________________________________________________________________________________________\nactivation_153 (Activation)     (None, 15, 15, 256)  0           add_73[0][0]                     \n__________________________________________________________________________________________________\nconv2d_444 (Conv2D)             (None, 15, 15, 256)  590080      activation_153[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_232 (BatchN (None, 15, 15, 256)  1024        conv2d_444[0][0]                 \n__________________________________________________________________________________________________\nactivation_154 (Activation)     (None, 15, 15, 256)  0           batch_normalization_232[0][0]    \n__________________________________________________________________________________________________\nconv2d_445 (Conv2D)             (None, 15, 15, 256)  590080      activation_154[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_233 (BatchN (None, 15, 15, 256)  1024        conv2d_445[0][0]                 \n__________________________________________________________________________________________________\nadd_74 (Add)                    (None, 15, 15, 256)  0           batch_normalization_233[0][0]    \n                                                                 activation_153[0][0]             \n__________________________________________________________________________________________________\nactivation_155 (Activation)     (None, 15, 15, 256)  0           add_74[0][0]                     \n__________________________________________________________________________________________________\nconv2d_446 (Conv2D)             (None, 15, 15, 256)  590080      activation_155[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_234 (BatchN (None, 15, 15, 256)  1024        conv2d_446[0][0]                 \n__________________________________________________________________________________________________\nactivation_156 (Activation)     (None, 15, 15, 256)  0           batch_normalization_234[0][0]    \n__________________________________________________________________________________________________\nconv2d_447 (Conv2D)             (None, 15, 15, 256)  590080      activation_156[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_235 (BatchN (None, 15, 15, 256)  1024        conv2d_447[0][0]                 \n__________________________________________________________________________________________________\nadd_75 (Add)                    (None, 15, 15, 256)  0           batch_normalization_235[0][0]    \n                                                                 activation_155[0][0]             \n__________________________________________________________________________________________________\nactivation_157 (Activation)     (None, 15, 15, 256)  0           add_75[0][0]                     \n__________________________________________________________________________________________________\nconv2d_448 (Conv2D)             (None, 15, 15, 256)  590080      activation_157[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_236 (BatchN (None, 15, 15, 256)  1024        conv2d_448[0][0]                 \n__________________________________________________________________________________________________\nactivation_158 (Activation)     (None, 15, 15, 256)  0           batch_normalization_236[0][0]    \n__________________________________________________________________________________________________\nconv2d_449 (Conv2D)             (None, 15, 15, 256)  590080      activation_158[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_237 (BatchN (None, 15, 15, 256)  1024        conv2d_449[0][0]                 \n__________________________________________________________________________________________________\nadd_76 (Add)                    (None, 15, 15, 256)  0           batch_normalization_237[0][0]    \n                                                                 activation_157[0][0]             \n__________________________________________________________________________________________________\nactivation_159 (Activation)     (None, 15, 15, 256)  0           add_76[0][0]                     \n__________________________________________________________________________________________________\nconv2d_450 (Conv2D)             (None, 8, 8, 512)    1180160     activation_159[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_238 (BatchN (None, 8, 8, 512)    2048        conv2d_450[0][0]                 \n__________________________________________________________________________________________________\nactivation_160 (Activation)     (None, 8, 8, 512)    0           batch_normalization_238[0][0]    \n__________________________________________________________________________________________________\nconv2d_451 (Conv2D)             (None, 8, 8, 512)    2359808     activation_160[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_239 (BatchN (None, 8, 8, 512)    2048        conv2d_451[0][0]                 \n__________________________________________________________________________________________________\nconv2d_452 (Conv2D)             (None, 8, 8, 512)    131584      activation_159[0][0]             \n__________________________________________________________________________________________________\nadd_77 (Add)                    (None, 8, 8, 512)    0           batch_normalization_239[0][0]    \n                                                                 conv2d_452[0][0]                 \n__________________________________________________________________________________________________\nactivation_161 (Activation)     (None, 8, 8, 512)    0           add_77[0][0]                     \n__________________________________________________________________________________________________\nconv2d_453 (Conv2D)             (None, 8, 8, 512)    2359808     activation_161[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_240 (BatchN (None, 8, 8, 512)    2048        conv2d_453[0][0]                 \n__________________________________________________________________________________________________\nactivation_162 (Activation)     (None, 8, 8, 512)    0           batch_normalization_240[0][0]    \n__________________________________________________________________________________________________\nconv2d_454 (Conv2D)             (None, 8, 8, 512)    2359808     activation_162[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_241 (BatchN (None, 8, 8, 512)    2048        conv2d_454[0][0]                 \n__________________________________________________________________________________________________\nadd_78 (Add)                    (None, 8, 8, 512)    0           batch_normalization_241[0][0]    \n                                                                 activation_161[0][0]             \n__________________________________________________________________________________________________\nactivation_163 (Activation)     (None, 8, 8, 512)    0           add_78[0][0]                     \n__________________________________________________________________________________________________\nconv2d_455 (Conv2D)             (None, 8, 8, 512)    2359808     activation_163[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_242 (BatchN (None, 8, 8, 512)    2048        conv2d_455[0][0]                 \n__________________________________________________________________________________________________\nactivation_164 (Activation)     (None, 8, 8, 512)    0           batch_normalization_242[0][0]    \n__________________________________________________________________________________________________\nconv2d_456 (Conv2D)             (None, 8, 8, 512)    2359808     activation_164[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_243 (BatchN (None, 8, 8, 512)    2048        conv2d_456[0][0]                 \n__________________________________________________________________________________________________\nadd_79 (Add)                    (None, 8, 8, 512)    0           batch_normalization_243[0][0]    \n                                                                 activation_163[0][0]             \n__________________________________________________________________________________________________\nactivation_165 (Activation)     (None, 8, 8, 512)    0           add_79[0][0]                     \n__________________________________________________________________________________________________\naverage_pooling2d_4 (AveragePoo (None, 4, 4, 512)    0           activation_165[0][0]             \n__________________________________________________________________________________________________\nflatten_25 (Flatten)            (None, 8192)         0           average_pooling2d_4[0][0]        \n__________________________________________________________________________________________________\ndense_71 (Dense)                (None, 512)          4194816     flatten_25[0][0]                 \n__________________________________________________________________________________________________\ndense_72 (Dense)                (None, 5749)         2949237     dense_71[0][0]                   \n==================================================================================================\nTotal params: 28,450,677\nTrainable params: 28,435,445\nNon-trainable params: 15,232\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"r = model2.fit(\n  training_set,\n  validation_data=test_set,\n  epochs=15,\n  steps_per_epoch=len(training_set),\n  validation_steps=len(test_set),\n)","metadata":{"execution":{"iopub.status.busy":"2022-11-23T16:58:27.344541Z","iopub.execute_input":"2022-11-23T16:58:27.344860Z","iopub.status.idle":"2022-11-23T17:33:57.854100Z","shell.execute_reply.started":"2022-11-23T16:58:27.344830Z","shell.execute_reply":"2022-11-23T17:33:57.853388Z"},"trusted":true},"execution_count":126,"outputs":[{"name":"stdout","text":"Epoch 1/15\n290/290 [==============================] - 141s 486ms/step - loss: 8.3993 - accuracy: 0.0317 - val_loss: 8.3569 - val_accuracy: 0.0414\nEpoch 2/15\n290/290 [==============================] - 142s 489ms/step - loss: 7.8299 - accuracy: 0.0389 - val_loss: 11.9129 - val_accuracy: 0.0331\nEpoch 3/15\n290/290 [==============================] - 142s 489ms/step - loss: 7.7453 - accuracy: 0.0388 - val_loss: 124.0894 - val_accuracy: 0.0377\nEpoch 4/15\n290/290 [==============================] - 142s 489ms/step - loss: 7.6834 - accuracy: 0.0392 - val_loss: 8.9940 - val_accuracy: 0.0422\nEpoch 5/15\n290/290 [==============================] - 141s 487ms/step - loss: 7.6261 - accuracy: 0.0391 - val_loss: 8.8414 - val_accuracy: 0.0419\nEpoch 6/15\n290/290 [==============================] - 141s 487ms/step - loss: 7.5866 - accuracy: 0.0394 - val_loss: 9.4165 - val_accuracy: 0.0346\nEpoch 7/15\n290/290 [==============================] - 142s 488ms/step - loss: 7.4580 - accuracy: 0.0397 - val_loss: 9.3645 - val_accuracy: 0.0417\nEpoch 8/15\n290/290 [==============================] - 141s 487ms/step - loss: 7.3318 - accuracy: 0.0404 - val_loss: 8.9936 - val_accuracy: 0.0424\nEpoch 9/15\n290/290 [==============================] - 141s 487ms/step - loss: 7.1994 - accuracy: 0.0416 - val_loss: 15.5010 - val_accuracy: 0.0324\nEpoch 10/15\n290/290 [==============================] - 141s 488ms/step - loss: 7.0915 - accuracy: 0.0429 - val_loss: 9.3045 - val_accuracy: 0.0457\nEpoch 11/15\n290/290 [==============================] - 141s 486ms/step - loss: 6.9791 - accuracy: 0.0429 - val_loss: 9.8256 - val_accuracy: 0.0454\nEpoch 12/15\n290/290 [==============================] - 139s 480ms/step - loss: 6.8314 - accuracy: 0.0456 - val_loss: 9.8543 - val_accuracy: 0.0457\nEpoch 13/15\n290/290 [==============================] - 140s 483ms/step - loss: 6.7631 - accuracy: 0.0466 - val_loss: 10.2199 - val_accuracy: 0.0475\nEpoch 14/15\n290/290 [==============================] - 141s 487ms/step - loss: 6.6116 - accuracy: 0.0480 - val_loss: 10.3256 - val_accuracy: 0.0472\nEpoch 15/15\n290/290 [==============================] - 141s 488ms/step - loss: 6.5023 - accuracy: 0.0497 - val_loss: 10.9719 - val_accuracy: 0.0469\n","output_type":"stream"}]},{"cell_type":"code","source":"# Import Keras modules and its important APIs\nimport keras\nfrom keras.layers import Dense, Conv2D, BatchNormalization, Activation\nfrom keras.layers import AveragePooling2D, Input, Flatten\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.regularizers import l2\nfrom keras import backend as K\nfrom keras.models import Model\nfrom keras.datasets import cifar10\nimport numpy as np\nimport os","metadata":{"execution":{"iopub.status.busy":"2022-11-23T16:21:18.599326Z","iopub.execute_input":"2022-11-23T16:21:18.599651Z","iopub.status.idle":"2022-11-23T16:21:18.606164Z","shell.execute_reply.started":"2022-11-23T16:21:18.599622Z","shell.execute_reply":"2022-11-23T16:21:18.605289Z"},"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"code","source":"model2.save(\"model.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-11-23T17:37:08.673322Z","iopub.execute_input":"2022-11-23T17:37:08.673645Z","iopub.status.idle":"2022-11-23T17:37:10.014921Z","shell.execute_reply.started":"2022-11-23T17:37:08.673617Z","shell.execute_reply":"2022-11-23T17:37:10.010472Z"},"trusted":true},"execution_count":131,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\n","metadata":{"execution":{"iopub.status.busy":"2022-11-23T17:39:49.401902Z","iopub.execute_input":"2022-11-23T17:39:49.402262Z","iopub.status.idle":"2022-11-23T17:39:49.406538Z","shell.execute_reply.started":"2022-11-23T17:39:49.402229Z","shell.execute_reply":"2022-11-23T17:39:49.405638Z"},"trusted":true},"execution_count":135,"outputs":[]},{"cell_type":"code","source":"modelnew = load_model(\"/kaggle/working/model.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-11-23T17:40:01.071076Z","iopub.execute_input":"2022-11-23T17:40:01.071443Z","iopub.status.idle":"2022-11-23T17:40:03.390155Z","shell.execute_reply.started":"2022-11-23T17:40:01.071411Z","shell.execute_reply":"2022-11-23T17:40:03.389282Z"},"trusted":true},"execution_count":137,"outputs":[]},{"cell_type":"code","source":"modelnew.evaluate(test_set)","metadata":{"execution":{"iopub.status.busy":"2022-11-23T17:40:06.156170Z","iopub.execute_input":"2022-11-23T17:40:06.156528Z","iopub.status.idle":"2022-11-23T17:40:21.714487Z","shell.execute_reply.started":"2022-11-23T17:40:06.156496Z","shell.execute_reply":"2022-11-23T17:40:21.713565Z"},"trusted":true},"execution_count":138,"outputs":[{"name":"stdout","text":"125/125 [==============================] - 14s 115ms/step - loss: 10.9719 - accuracy: 0.0469\n","output_type":"stream"},{"execution_count":138,"output_type":"execute_result","data":{"text/plain":"[10.971924781799316, 0.046949535608291626]"},"metadata":{}}]},{"cell_type":"code","source":"predictions = modelnew.predict_generator(test_set)\npredicted_classes = np.argmax(predictions, axis=1)\ntrue_classes = test_set.classes\nclass_labels = list(test_set.class_indices.keys())","metadata":{"execution":{"iopub.status.busy":"2022-11-23T17:40:25.917588Z","iopub.execute_input":"2022-11-23T17:40:25.917901Z","iopub.status.idle":"2022-11-23T17:40:39.879237Z","shell.execute_reply.started":"2022-11-23T17:40:25.917872Z","shell.execute_reply":"2022-11-23T17:40:39.878444Z"},"trusted":true},"execution_count":139,"outputs":[]},{"cell_type":"code","source":"confusion_matrix = confusion_matrix(true_classes, predicted_classes)","metadata":{"execution":{"iopub.status.busy":"2022-11-23T17:42:02.869705Z","iopub.execute_input":"2022-11-23T17:42:02.870040Z","iopub.status.idle":"2022-11-23T17:42:02.903511Z","shell.execute_reply.started":"2022-11-23T17:42:02.870010Z","shell.execute_reply":"2022-11-23T17:42:02.902757Z"},"trusted":true},"execution_count":140,"outputs":[]},{"cell_type":"code","source":"np.seterr(divide='ignore', invalid='ignore')\nFP = confusion_matrix.sum(axis=0) - np.diag(confusion_matrix)  \nFN = confusion_matrix.sum(axis=1) - np.diag(confusion_matrix)\nTP = np.diag(confusion_matrix)\nTN = confusion_matrix.sum() - (FP + FN + TP)\nFPR = FP/(FP+TN)\nTPR = TP/(TP+FN)","metadata":{"execution":{"iopub.status.busy":"2022-11-23T17:42:06.149671Z","iopub.execute_input":"2022-11-23T17:42:06.149991Z","iopub.status.idle":"2022-11-23T17:42:06.181749Z","shell.execute_reply.started":"2022-11-23T17:42:06.149960Z","shell.execute_reply":"2022-11-23T17:42:06.180830Z"},"trusted":true},"execution_count":141,"outputs":[]},{"cell_type":"code","source":"print(FPR, TPR)","metadata":{"execution":{"iopub.status.busy":"2022-11-23T17:42:09.099085Z","iopub.execute_input":"2022-11-23T17:42:09.099424Z","iopub.status.idle":"2022-11-23T17:42:09.105088Z","shell.execute_reply.started":"2022-11-23T17:42:09.099393Z","shell.execute_reply":"2022-11-23T17:42:09.104085Z"},"trusted":true},"execution_count":142,"outputs":[{"name":"stdout","text":"[0. 0. 0. ... 0. 0. 0.] [0. 0. 0. ... 0. 0. 0.]\n","output_type":"stream"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nx = FPR\ny = TPR\n\n# This is the ROC curve\nplt.plot(x,y)\nplt.show() \n\n# This is the AUC\nauc = np.trapz(y,x)","metadata":{"execution":{"iopub.status.busy":"2022-11-23T17:42:11.862750Z","iopub.execute_input":"2022-11-23T17:42:11.863074Z","iopub.status.idle":"2022-11-23T17:42:12.049361Z","shell.execute_reply.started":"2022-11-23T17:42:11.863044Z","shell.execute_reply":"2022-11-23T17:42:12.048295Z"},"trusted":true},"execution_count":143,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deXhU9dnG8e9D2BdBWUSBCCKKimwOOyK7iL5SKVWk1WqtiIqVVqxaRRGqWLUu1IWCxVqtUltFqaKgLAIFJGEVEGVTCIjIIsgSyPJ7/0g8iTGSkzCTM3Nyf66LyzxzTuY8PyfcTM7MPMecc4iISOIrF3QDIiISHQp0EZGQUKCLiISEAl1EJCQU6CIiIVE+qAPXqVPHNW7cOKjDi4gkpKVLl+5yztUtbFtggd64cWNSU1ODOryISEIysy9+bJtOuYiIhIQCXUQkJBToIiIhoUAXEQkJBbqISEgo0EVEQkKBLiISEgp0EZFSkp6RxXUvLGHpF3tjcv+BfbBIRKQseS11K7//zyoAksoZz/+yXdSPoUAXEYmhfYczaPXATK/+SetTeXJwm5gcS4EuIhIjEz7cyMPvrvPqeXf0ILl21ZgdT4EuIhJlO/en0/6hWV59Y7fTubv/2TE/rgJdRCSKxr69lr8t2OzVKff0pm6NSqVybAW6iEgUfL7rIN0fm+vV9/Q/mxu6nV6qPSjQRUSO062vLue/K7d79arRfTmhcoVS70OBLiJSQqu37ePSvyzw6sd+1opB5zcMrB8FuohIMWVnOwZPWsySzXsAOLFqBRbd3YvKFZIC7UuBLiJSDAs37mLIpI+8evK1EXo2PznAjvIo0EVEfMjIyqb34x/yxe5DADSvX4N3fnMBSeUs4M7yKNBFRIrw3uovGfbyMq/+z7BORBqfFGBHhVOgi4j8iMNHs2gzdibpGdkAdDuzLi9e1w6z+HlWnp+vQDezfsBTQBLwvHPu4UL26Q48CVQAdjnnLoxinyIipeqVj7bwh6kfe/WMEd04q36NADsqWpGBbmZJwDNAHyANSDGzac65tfn2qQU8C/Rzzm0xs3qxalhEJJb2Hcqg1Zi8YVqDzm/IYz9rFWBH/vl5ht4e2OCc2wRgZlOAAcDafPsMAd5wzm0BcM7tjHajIiKx9vTs9Tw28zOvnv/7HjQ6KXbDtKLNT6A3ALbmq9OADgX2OROoYGZzgRrAU865fxS8IzMbCgwFSE5OLkm/IiJRt2NfOh3H5Q3TuqVHU+64qHmAHZWMn0Av7Oy/K+R+zgd6AVWARWa22Dn32fe+ybmJwESASCRS8D5ERErd/W+t5sVFX3j10nt7U7t66QzTijY/gZ4GNMpXNwS2F7LPLufcQeCgmc0DWgGfISIShzZ+fYBef/7Qq++79Bx+1bVJgB0dPz+BngI0M7MmwDZgMDnnzPN7C3jazMoDFck5JfNENBsVEYkG5xw3/3MZ767e4d22+oGLqF4p8d/FXeQKnHOZZjYcmEHO2xYnO+fWmNmw3O0TnHOfmNl7wCogm5y3Nq6OZeMiIsW1Ku0bLnv6f1791ODWDGjdIMCOosucC+ZUdiQScampqYEcW0TKluxsx8DnFrJi6zcA1KtRifl39qBS+WCHaZWEmS11zkUK25b4v2OIiBzDgvW7+MXf8oZp/f26dnQ/K5wflVGgi0goHc3Mpvujc9i+Lx2A8xrU5M1busTVMK1oU6CLSOi8vWo7w19Z7tVv3NyZtsknBthR6VCgi0hoHDqayXmjZ5KVnfPaYO+z6zHpmkjcDtOKNgW6iITCS4s+Z9Rba7z6g99144x68T1MK9oU6CKS0PYePEqbse979VXtkxk38LwAOwqOAl1EEtYT73/GU7PWe/XCu3pyaq0qAXYULAW6iCSc7d8cpvPDs736N72a8bs+ZwbYUXxQoItIQvnD1I955aMtXr1sVB9OqlYxwI7ihwJdRBLChp3f0vvxeV49ZsC5XNOpcXANxSEFuojENeccN/wjlQ8+ybluTlI5Y9X9fakWgmFa0ab/IyISt5Zt2cvAZxd69dND2nBpy1MD7Ci+KdBFJO5kZTsGPLOA1dv2A9CgVhXmjOxOxfLlAu4svinQRSSuzP10J9e+kOLVL1/fga7N6gTYUeJQoItIXDiSmUXXP83h62+PANAmuRavD+tMuRAP04o2BbqIBO6tFdu4bcqKvPqWLrRqVCvAjhKTAl1EAnPgSCYt7p/h1Re3qM+zP29bZoZpRZsCXUQCMXnBZsa8vdarZ99+IafXrR5gR4lPgS4ipWr3gSOc/8cPvPqXnU7jgQEtAuwoPBToIlJqHp2xjmfmbPTqxXf3on7NygF2FC4KdBGJubS9h+j6pzlefXufM7m1V7MAOwonX4FuZv2Ap4Ak4Hnn3MMFtncH3gI25970hnNuTBT7FJEE9fv/rOS11DSvXnFfH2pV1TCtWCgy0M0sCXgG6AOkASlmNs05t7bArvOdc5fGoEcRSUCf7viWi57MG6b10OXnMaRDcoAdhZ+fZ+jtgQ3OuU0AZjYFGAAUDHQREZxz/PKFFOZ99jUAlSuUY/movlSpmBRwZ+HnJ9AbAFvz1WlAh0L262RmK4HtwEjn3JqCO5jZUGAoQHKy/qUWCZvUz/cwaMIir57wi7b0a3FKgB2VLX4CvbB3+LsC9TLgNOfcATPrD7wJ/OAVD+fcRGAiQCQSKXgfIpKgsrIdl4yfz7od3wJwWu2qfPC7C6mQpGFapclPoKcBjfLVDcl5Fu5xzu3P9/V0M3vWzOo453ZFp00RiVez133Fr/6e6tWv3NCBzk01TCsIfgI9BWhmZk2AbcBgYEj+HcysPvCVc86ZWXugHLA72s2KSPxIz8ii07hZ7D2UAUD7xicxZWhHDdMKUJGB7pzLNLPhwAxy3rY42Tm3xsyG5W6fAAwCbjKzTOAwMNg5p1MqIiH1+tI0bv/3Sq9++9autGhQM8COBMCCyt1IJOJSU1OL3lFE4sb+9Axajp7p1Ze1OpXxV7UJsKOyx8yWOucihW3TJ0VFxJdJ8zbx4PRPvHruyO40rlMtwI6kIAW6iBzT198eod2DecO0ru/ahFGXnhNgR/JjFOgi8qPGvfsJf/1wk1cv+UMv6p2gYVrxSoEuIj+wZfchuj2aN0zrzn7Nual70wA7Ej8U6CLyPb/91wqmLt/m1Svv70vNKhUC7Ej8UqCLCABrt++n//j5Xv3IT1tyRbtGx/gOiTcKdJEyzjnHkEkfsWhTzmcBa1QqT8q9valcQcO0Eo0CXaQM+2jTbq6cuNirJ159Pn3PrR9gR3I8FOgiZVBmVjZ9n5zHpq8PAtC0bjVmjOhGeQ3TSmgKdJEyZsaaHdz40lKv/tfQjnQ4vXaAHUm0KNBFyoj0jCzOH/s+B49mAdDljNq8fH0HzDRMKywU6CJlwGspW/n966u8+t3bLuDsU04IsCOJBQW6SIjtO5xBqwfyhmld3qYBT1zZOsCOJJYU6CIh9dzcjfzpvXVePe+OHiTXrhpgRxJrCnSRkNm5P532D83y6hu7nc7d/c8OsCMpLQp0kRAZ89+1TP7fZq9Ouac3dWtUCrAjKU0KdJEQ2LzrID0em+vV9/Q/mxu6nR5cQxIIBbpIAnPOceury3l71ZfebR+P7kuNyhqmVRYp0EUS1Opt+7j0Lwu8+vErWjGwbcMAO5KgKdBFEkx2tmPwxMUs+XwPACdWrcCiu3tpmJYo0EUSycKNuxgy6SOvnnxthJ7NTw6wI4knCnSRBJCRlU3PP89l657DADSvX4N3fnMBSeX0sX3J42u0mpn1M7NPzWyDmd11jP3amVmWmQ2KXosiZdu7H39Js3ve9cL89Zs68d6Ibgpz+YEin6GbWRLwDNAHSANSzGyac25tIfv9CZgRi0ZFyprDR7NoNWYmRzOzAeh+Vl1euLadhmnJj/JzyqU9sME5twnAzKYAA4C1Bfa7FXgdaBfVDkXKoFc+2sIfpn7s1TNGdOOs+jUC7EgSgZ9AbwBszVenAR3y72BmDYDLgZ4cI9DNbCgwFCA5Obm4vYqE3jeHjtJ6zPtefUWkIY8MahVgR5JI/AR6Yb/fuQL1k8CdzrmsY/066JybCEwEiEQiBe9DpEx7evZ6Hpv5mVfP/30PGp2kYVrin59ATwPyX/q7IbC9wD4RYEpumNcB+ptZpnPuzah0KRJiO/al03Fc3jCtW3o05Y6LmgfYkSQqP4GeAjQzsybANmAwMCT/Ds65Jt99bWZ/B95WmIsU7b63VvOPRV949dJ7e1O7uoZpSckUGejOuUwzG07Ou1eSgMnOuTVmNix3+4QY9ygSOhu/PkCvP3/o1ff/3zlc16XJMb5DpGi+PljknJsOTC9wW6FB7py79vjbEgkn5xzDXl7KjDVfebetfuAiqlfSZ/zk+OmnSKSUrEr7hsue/p9XPzW4NQNaNwiwIwkbBbpIjGVnOwY+t5AVW78BoF6NSsy/sweVymuYlkSXAl0khuav/5qr/7bEq/9+XTu6n1UvwI4kzBToIjFwNDObCx+dw5f70gE4r0FN3ryli+avSEwp0EWi7L8rt3Prq8u9eurNnWmTfGKAHUlZoUAXiZKDRzI5b/QMsnM/A9377JOZdM35GqYlpUaBLhIFLy36nFFvrfHqD37XjTPqaZiWlC4Fushx2HvwKG3G5g3Tuqp9MuMGnhdgR1KWKdBFSujx9z9j/Kz1Xr3wrp6cWqtKgB1JWadAFymmbd8cpsvDs736tl7N+G2fMwPsSCSHAl2kGO5+YxWvLsm7PMDyUX04sVrFADsSyaNAF/Fh/Vff0ueJeV49dsC5XN2pcXANiRRCgS5yDM45fv1iKrPW7QSgfDlj1ei+VK2ovzoSf/RTKfIjlm3Zy8BnF3r100PacGnLUwPsSOTYFOgiBWRlOy57egFrtu8HoEGtKswZ2Z2K5csF3JnIsSnQRfKZ8+lOrnshxatfvr4DXZvVCbAjEf8U6CLAkcwsujw8h10HjgDQNrkW/xnWmXIapiUJRIEuZd6by7cx4l8rvHra8C60bFgrwI5ESkaBLmXWgSOZtLh/hldf3KI+z/68rYZpScJSoEuZ9LcFmxn79lqvnn37hZxet3qAHYkcPwW6lCm7Dhwh8scPvPqXnU7jgQEtAuxIJHp8BbqZ9QOeApKA551zDxfYPgAYC2QDmcAI59yCKPcqclweeW8dz87d6NWL7+5F/ZqVA+xIJLqKDHQzSwKeAfoAaUCKmU1zzq3Nt9ssYJpzzplZS+A1oHksGhYprq17DnHBI3O8emTfMxnes1mAHYnEhp9n6O2BDc65TQBmNgUYAHiB7pw7kG//aoCLZpMiJXXHv1fy76VpXr3yvr7UrFohwI5EYsdPoDcAtuar04AOBXcys8uBcUA94JLC7sjMhgJDAZKTk4vbq4hv63bsp9+T87163MDzuKq9fuYk3PwEemHv4frBM3Dn3FRgqpl1I+d8eu9C9pkITASIRCJ6Fi9R55zjmslLmL9+FwCVK5Rj+ai+VKmYFHBnIrHnJ9DTgEb56obA9h/b2Tk3z8yamlkd59yu421QxK/Uz/cwaMIir57wi7b0a3FKgB2JlC4/gZ4CNDOzJsA2YDAwJP8OZnYGsDH3RdG2QEVgd7SbFSlMZlY2/cfP57Ovcl7KaVy7Ku//7kIqJGmYlpQtRQa6cy7TzIYDM8h52+Jk59waMxuWu30C8FPgGjPLAA4DVzrndEpFYm7WJ19x/YupXv3qDR3p1LR2gB2JBMeCyt1IJOJSU1OL3lGkEOkZWXR4aBb7DmcA0KHJSbx6Q0cN05LQM7OlzrlIYdv0SVFJOK8vTeP2f6/06rdv7UqLBjUD7EgkPijQJWHsT8+g5eiZXn1Zq1MZf1WbADsSiS8KdEkIE+dt5KHp67x67sjuNK5TLcCOROKPAl3i2s5v02n/4Cyvvr5rE0Zdek6AHYnELwW6xK2Hpn/CxHmbvHrJH3pR7wQN0xL5MQp0iTtbdh+i26N5w7Tu7Necm7o3DbAjkcSgQJe4MmLKct5ckfdB5JX396VmFQ3TEvFDgS5xYc32fVwyPm+E/iM/bckV7Rod4ztEpCAFugTKOcdVkxazeNMeAGpUKk/Kvb2pXEHDtESKS4EugVm8aTeDJy726knXROhzzskBdiSS2BToUuoys7Lp+8Q8Nu06CMAZ9arz3m0XUF7DtESOiwJdStWMNTu48aWlXv3ajZ1o3+SkADsSCQ8FupSK9Iwszh/7PgePZgHQ5YzavHx9B8w0TEskWhToEnP/StnCna9/7NXv3nYBZ59yQoAdiYSTAl1iZt+hDFqNyRumNbBNAx6/snWAHYmEmwJdYuLZuRt45L1PvXreHT1Irl01wI5Ewk+BLlH11f50OjyUN0xr2IVNuevi5gF2JFJ2KNAlasb8dy2T/7fZq1Pu6U3dGpUC7EikbFGgy3HbvOsgPR6b69X3XnI2v77g9OAaEimjFOhSYs45hr+ynHc+/tK77ePRfalRWcO0RIKgQJcSWb1tH5f+JW+Y1uNXtGJg24YBdiQivgLdzPoBTwFJwPPOuYcLbP85cGdueQC4yTm3Egmd7GzHFX9dROoXewGoXa0i/7urp4ZpicSBIgPdzJKAZ4A+QBqQYmbTnHNr8+22GbjQObfXzC4GJgIdYtGwBGfhxl0MmfSRV0++NkLP5hqmJRIv/DxDbw9scM5tAjCzKcAAwAt059zCfPsvBvS7d4hkZGXT889z2brnMABnn3ICb9/alaRy+ti+SDzxE+gNgK356jSO/ez7euDdwjaY2VBgKEBycrLPFiVI7378JTf9c5lXv35TJ84/TcO0ROKRn0Av7GmYK3RHsx7kBHrXwrY75yaSczqGSCRS6H1IfDh0NJPWY97naGY2AN3PqssL17bTMC2ROOYn0NOA/NcCawhsL7iTmbUEngcuds7tjk57EoR/fvQF90xd7dUzRnTjrPo1AuxIRPzwE+gpQDMzawJsAwYDQ/LvYGbJwBvA1c65z6LepZSKbw4dpfWY9736ikhDHhnUKsCORKQ4igx051ymmQ0HZpDztsXJzrk1ZjYsd/sE4D6gNvBs7q/kmc65SOzalmgbP2s9j7+f92/xgjt70PBEDdMSSSTmXDCnsiORiEtNTQ3k2JJnx750Oo7LG6Y1vMcZjLzorAA7EpFjMbOlP/aEWZ8ULcNGvbmalxZ/4dVL7+1N7eoapiWSqBToZdCGnQfo/fiHXn3//53DdV2aBNiRiESDAr0Mcc5x40tLmbn2K++21Q9cRPVK+jEQCQP9TS4jVm79hgHP/M+rnxrcmgGtGwTYkYhEmwI95LKzHZc/t5CVW78BoF6NSsy/sweVymuYlkjYKNBDbP76r7n6b0u8+sVftefCM+sG2JGIxJICPYSOZmbT7ZE57NifDkDLhjWZenMXDdMSCTkFeshMW7md37y63Kun3tyZNsknBtiRiJQWBXpIHDySSYvRM/juc2K9zz6ZSdecr2FaImWIAj0EXlz4OfdPW+PVH/yuG2fU0zAtkbJGgZ7A9hw8StuxecO0ft4hmQcvPy/AjkQkSAr0BPX4zE8ZP3uDVy+8qyen1qoSYEciEjQFeoLZ9s1hujw826tH9G7GiN5nBtiRiMQLBXoCufuNVby6JO9qgMtH9eHEahUD7EhE4okCPQGs/+pb+jwxz6vH/qQFV3c8LcCORCQeKdDjmHOO619MZfa6nQCUL2esGt2XqhX1sInIDykZ4tTSL/by0+cWevUzQ9pySctTAuxIROKdAj3OZGU7Lnt6AWu27wegQa0qzBnZnYrlywXcmYjEOwV6HJnz6U6ueyHFq//56w50OaNOgB2JSCJRoMeBI5lZdB43m90HjwLQNrkW/xnWmXIapiUixaBAD9iby7cx4l8rvHra8C60bFgrwI5EJFH5OjFrZv3M7FMz22BmdxWyvbmZLTKzI2Y2Mvpths+36Rk0vusdL8z7n1efzeP6K8xFpMSKfIZuZknAM0AfIA1IMbNpzrm1+XbbA/wG+ElMugyZvy3YzNi38/73zb79Qk6vWz3AjkQkDPyccmkPbHDObQIwsynAAMBLJOfcTmCnmV0Sky6j5MCRzEAviLzrwBEif/zAq6/t3JjRl50bWD8iEi5+Trk0ALbmq9Nyb0soLy36nBb3z+CdVV8Gcvw/vbfue2G++O5eCnMRiSo/T1cLe6uFK8nBzGwoMBQgOTm5JHdRYqPeypkX3r7JSaV63K17DnHBI3O8emTfMxnes1mp9iAiZYOfQE8DGuWrGwLbS3Iw59xEYCJAJBIp0T8KJfHe6rxn5XVrVCqtw3L7ayt5fVmaV6+8ry81q1YoteOLSNniJ9BTgGZm1gTYBgwGhsS0qygb9vIyIOdKPqVh3Y799HtyvlePG3geV7Uv3d9IRKTsKTLQnXOZZjYcmAEkAZOdc2vMbFju9glmVh9IBU4Ass1sBHCOc25/DHv3ZdmWvd7Xsb4sm3OOayYvYf76XQBUqZDEslF9qFIxKabHFREBnx8scs5NB6YXuG1Cvq93kHMqJu4MfDZnwNWUoR1jepzUz/cwaMIir57wi7b0a6FhWiJSekL9SdEvdh/0vu54eu2YHCMzK5v+4+fz2VcHAGhSpxozf9uNCkkapiUipSvUgf7dRSGeGtw6Jvf/wdqv+PU/Ur361Rs60qlpbP7hEBEpSmgDfe/BoxzNzAZgQOvovm0+PSOL9g9+wP70TAA6NDmJV2/oqGFaIhKo0Ab6z/6acz77jovOiur9/mdpGiP/vdKr3761Ky0a1IzqMURESiKUgZ6ekcWGnTnntG/u3jQq97k/PYOWo2d69WWtTmX8VW2ict8iItEQykC/+Z857zu/ItIQs+M/DTJx3kYemr7Oq+eO7E7jOtWO+35FRKIpdIGene28iyqPG9jyuO5r57fptH9wlldf37UJoy4957juU0QkVkIX6GNyx9J2PP0kko7jRcoH31nLpPmbvXrJH3pR74TKx92fiEishC7Q/77wcwAmX9uuRN//xe6DXPjoXK++6+LmDLswOufhRURiKVSB/vz8TQA0qFWFqhWLv7TbpiznrRV5c8dW3t+XmlU0TEtEEkOoAv2P73wCwNRbOhfr+9Zs38cl4xd49SODWnJFpNExvkNEJP6EJtDzj8itV8PfuW7nHIMnLuajzXsAqFG5PCn39KZyBQ3TEpHEE5pAL+6I3EUbd3PVpMVePemaCH3OOTkmvYmIlIZQBHpxRuRmZmXT54l5bN6VM7irWb3qvHvbBZTXMC0RSXChCPTvRuS+esOxR+S+t3oHw15e6tWv3dip1C9JJyISKwkf6PlH5P7YpMP0jCzOvX8GWdk5V73rekYdXrq+fVQ+RSoiEi8SPtC/G5H75JWFj8j9V8oW7nz9Y69+5YYOdG5ap1R6ExEpTQkd6PlH5P6kzfdH5O47lEGrMTO/d9vgdo0U5iISWgkd6N+NyB3Z98zv3f7E+5/x1Kz137tt2ag+nFStYqn1JiJS2hI20POPyL2lxxkAfLU/nQ4PzfrefpOvjdCzud6OKCLhl7CBXnBE7pBJi1m4cbe3XS98ikhZk5CBnn9E7nVdmtD4rne+tz313t7UqV4piNZERALj69M0ZtbPzD41sw1mdlch283MxuduX2VmbaPfap7vRuQCXPzUfO/rx69oxecPX6IwF5Eyqchn6GaWBDwD9AHSgBQzm+acW5tvt4uBZrl/OgDP5f43Jr4bkZvf5nH9dXpFRMo0P6dc2gMbnHObAMxsCjAAyB/oA4B/OOccsNjMapnZKc65L394d8en4OmV7zS5e3rUjnHWyTWY8Vt/M2FEROKFn1MuDYCt+eq03NuKuw9mNtTMUs0s9euvvy5urwA0OqlKib6vOFo1qhnzY4iIRJufZ+iFncdwJdgH59xEYCJAJBL5wXY/5v++Z0m+TUQk9Pw8Q08D8l/toSGwvQT7iIhIDPkJ9BSgmZk1MbOKwGBgWoF9pgHX5L7bpSOwLxbnz0VE5McVecrFOZdpZsOBGUASMNk5t8bMhuVunwBMB/oDG4BDwHWxa1lERArj64NFzrnp5IR2/tsm5PvaAbdEtzURESkOXaZHRCQkFOgiIiGhQBcRCQkFuohISFjO65kBHNjsa+CLEn57HWBXFNsJShjWoTXEhzCsAcKxjliv4TTnXN3CNgQW6MfDzFKdc5Gg+zheYViH1hAfwrAGCMc6glyDTrmIiISEAl1EJCQSNdAnBt1AlIRhHVpDfAjDGiAc6whsDQl5Dl1ERH4oUZ+hi4hIAQp0EZGQiOtAj7eLU5eEjzU0N7NFZnbEzEYG0aMfPtbx89zHYJWZLTSzVkH0eSw+1jAgt/8VuVfW6hpEn8dS1Bry7dfOzLLMbFBp9ueHj8ehu5nty30cVpjZfUH0WRQ/j0XuWlaY2Roz+zDmTTnn4vIPOaN6NwKnAxWBlcA5BfbpD7xLzhWTOgIfBd13CdZQD2gHPAiMDLrn41hHZ+DE3K8vTtDHojp5ryu1BNYF3Xdx15Bvv9nkTEgdFHTfJXgcugNvB91rFNZRi5xrLyfn1vVi3Vc8P0P3Lk7tnDsKfHdx6vy8i1M75xYDtczslNJu9BiKXINzbqdzLgXICKJBn/ysY6Fzbm9uuZicq1bFEz9rOOBy/+YB1SjkMooB8/N3AuBW4HVgZ2k255PfNcQ7P+sYArzhnNsCOX/XY91UPAd61C5OHaB478+v4q7jenJ+c4onfi9kfrmZrQPeAX5VSr35VeQazKwBcDkwgfjk92epk5mtNLN3zezc0mmtWPys40zgRDOba2ZLzeyaWDfl6wIXAYnaxakDFO/9+eV7HWbWg5xAj7fzz34vZD4VmGpm3YCxQO9YN1YMftbwJHCncy7LrLDdA+dnDcvImVdywMz6A28CzWLeWfH4WUd54HygF1AFWGRmi51zn8WqqXgO9DBcnDre+/PL1zrMrCXwPHCxc253KfXmV7EeC+fcPDNramZ1nHPxMizKzxoiwJTcMK8D9DezTOfcm6XTYpGKXINzbn++r6eb2bNx9jiA/3za5Zw7CBw0s3lAKyBmgR74iwvHeNGhPLAJaELeiw7nFtjnEr7/ouiSoPsu7hry7Tua+H1R1LIGwmkAAADeSURBVM9jkUzONWU7B93vcazhDPJeFG0LbPuujoc/xfl5yt3/78Tfi6J+Hof6+R6H9sCWeHocirGOs4FZuftWBVYDLWLZV9w+Q3chuDi1nzWYWX0gFTgByDazEeS8Wr7/R++4lPl8LO4DagPP5j47zHRxNDXP5xp+ClxjZhnAYeBKl/s3Mx74XENc87mGQcBNZpZJzuMwOJ4eB/C3DufcJ2b2HrAKyAaed86tjmVf+ui/iEhIxPO7XEREpBgU6CIiIaFAFxEJCQW6iEhIKNBFREJCgS4iEhIKdBGRkPh/w0VPZC3QoPQAAAAASUVORK5CYII=\n"},"metadata":{"needs_background":"light"}}]}]}